{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9062dee-4dc0-4db6-84e0-e0c77e6fb485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239d6776-138d-4154-8fe0-f2fa5f30cc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting cleverhans\n",
      "  Downloading cleverhans-4.0.0-py3-none-any.whl.metadata (846 bytes)\n",
      "Collecting foolbox\n",
      "  Downloading foolbox-3.3.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting nose (from cleverhans)\n",
      "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycodestyle (from cleverhans)\n",
      "  Using cached pycodestyle-2.12.1-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from cleverhans) (1.10.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from cleverhans) (3.7.5)\n",
      "Collecting mnist (from cleverhans)\n",
      "  Downloading mnist-0.2.2-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from cleverhans) (1.24.3)\n",
      "Collecting tensorflow-probability (from cleverhans)\n",
      "  Downloading tensorflow_probability-0.21.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from cleverhans) (1.4.2)\n",
      "Collecting easydict (from cleverhans)\n",
      "  Downloading easydict-1.13-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\abhis\\appdata\\roaming\\python\\python38\\site-packages (from cleverhans) (2.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from cleverhans) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from foolbox) (75.1.0)\n",
      "Collecting eagerpy>=0.30.0 (from foolbox)\n",
      "  Downloading eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: GitPython>=3.0.7 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from foolbox) (3.1.44)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from foolbox) (4.11.0)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from foolbox) (2.32.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from GitPython>=3.0.7->foolbox) (4.0.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from requests>=2.24.0->foolbox) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from requests>=2.24.0->foolbox) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from requests>=2.24.0->foolbox) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from requests>=2.24.0->foolbox) (2024.8.30)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib->cleverhans) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib->cleverhans) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib->cleverhans) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib->cleverhans) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib->cleverhans) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib->cleverhans) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib->cleverhans) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib->cleverhans) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from matplotlib->cleverhans) (6.4.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from tensorflow-probability->cleverhans) (5.1.1)\n",
      "Collecting cloudpickle>=1.3 (from tensorflow-probability->cleverhans)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gast>=0.3.2 (from tensorflow-probability->cleverhans)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting dm-tree (from tensorflow-probability->cleverhans)\n",
      "  Downloading dm_tree-0.1.8-cp38-cp38-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting typing-extensions>=3.7.4.1 (from foolbox)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->cleverhans) (3.20.2)\n",
      "Downloading cleverhans-4.0.0-py3-none-any.whl (92 kB)\n",
      "Downloading foolbox-3.3.4-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.0/1.7 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
      "Downloading easydict-1.13-py3-none-any.whl (6.8 kB)\n",
      "Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "Using cached pycodestyle-2.12.1-py2.py3-none-any.whl (31 kB)\n",
      "Downloading tensorflow_probability-0.21.0-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/6.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.3/6.9 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.1/6.9 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.9/6.9 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.4/6.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.2/6.9 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.7/6.9 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.5/6.9 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.0/6.9 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/6.9 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading dm_tree-0.1.8-cp38-cp38-win_amd64.whl (101 kB)\n",
      "Installing collected packages: nose, easydict, dm-tree, typing-extensions, pycodestyle, mnist, gast, cloudpickle, tensorflow-probability, eagerpy, foolbox, cleverhans\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "Successfully installed cleverhans-4.0.0 cloudpickle-3.1.1 dm-tree-0.1.8 eagerpy-0.30.0 easydict-1.13 foolbox-3.3.4 gast-0.6.0 mnist-0.2.2 nose-1.3.7 pycodestyle-2.12.1 tensorflow-probability-0.21.0 typing-extensions-4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.4.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# core libraries\n",
    "! pip install torch torchvision numpy matplotlib\n",
    "# for attacks\n",
    "! pip install cleverhans foolbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f629a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp38-cp38-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp38-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp38-cp38-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py38-none-any.whl.metadata (7.1 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.10.11-cp38-cp38-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp38-cp38-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp38-cp38-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.15.2-cp38-cp38-win_amd64.whl.metadata (58 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets)\n",
      "  Downloading propcache-0.2.0-cp38-cp38-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 7.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.1/10.0 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.4/10.0 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.9/10.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.7/10.0 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.2/10.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.0/10.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.8/10.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.1/10.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.4/10.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.10.11-cp38-cp38-win_amd64.whl (384 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
      "Downloading pyarrow-17.0.0-cp38-cp38-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/25.2 MB 3.4 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.3/25.2 MB 3.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.8/25.2 MB 3.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 2.6/25.2 MB 3.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.1/25.2 MB 3.2 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 3.9/25.2 MB 3.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 4.5/25.2 MB 3.2 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 5.2/25.2 MB 3.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.0/25.2 MB 3.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 6.6/25.2 MB 3.1 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 7.1/25.2 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 7.9/25.2 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 8.7/25.2 MB 3.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 9.2/25.2 MB 3.2 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 10.0/25.2 MB 3.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.5/25.2 MB 3.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 11.3/25.2 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 11.8/25.2 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 12.6/25.2 MB 3.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 13.4/25.2 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.9/25.2 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.7/25.2 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.2/25.2 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 16.0/25.2 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.8/25.2 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 17.3/25.2 MB 3.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 18.1/25.2 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 18.6/25.2 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 19.4/25.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.9/25.2 MB 3.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.7/25.2 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 21.2/25.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.0/25.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.8/25.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.3/25.2 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.1/25.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/25.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp38-cp38-win_amd64.whl (274 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading tokenizers-0.20.3-cp38-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp38-cp38-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp38-cp38-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.1.0-cp38-cp38-win_amd64.whl (28 kB)\n",
      "Downloading yarl-1.15.2-cp38-cp38-win_amd64.whl (84 kB)\n",
      "Downloading propcache-0.2.0-cp38-cp38-win_amd64.whl (45 kB)\n",
      "Installing collected packages: xxhash, safetensors, regex, pyarrow, propcache, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.10.11 aiosignal-1.3.1 async-timeout-5.0.1 datasets-3.1.0 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.30.2 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.0 pyarrow-17.0.0 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.20.3 transformers-4.46.3 xxhash-3.5.0 yarl-1.15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.4.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324bfa00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTSdpaAttention(\n",
       "            (attention): ViTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "\n",
    "MODEL_ID = \"farleyknight-org-username/vit-base-mnist\"\n",
    "processor = ViTImageProcessor.from_pretrained(MODEL_ID)  # handles resize & normalize :contentReference[oaicite:2]{index=2}\n",
    "model     = ViTForImageClassification.from_pretrained(MODEL_ID)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbc3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f63337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Grayscale, Resize, ToTensor, Normalize\n",
    "\n",
    "transform = Compose([\n",
    "    Resize(224),                        # ViT input size :contentReference[oaicite:4]{index=4}\n",
    "    Grayscale(num_output_channels=3),   # convert to RGB\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5]*3, std=[0.5]*3)  # ViT normalization :contentReference[oaicite:5]{index=5}\n",
    "])\n",
    "\n",
    "train_ds = MNIST(root=\"data\", train=True,  download=True, transform=transform)\n",
    "test_ds  = MNIST(root=\"data\", train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa2726b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e869d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6778e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93c90ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:   0%|          | 0/157 [00:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "correct, total = 0, 0\n",
    "for batch in tqdm(test_loader, desc=\"Eval\"):\n",
    "    pixel_values = batch[0]  # shape: [B, 3, 224, 224]\n",
    "    labels       = batch[1]\n",
    "    with torch.no_grad():\n",
    "        logits = model(pixel_values).logits  # ViTForImageClassification returns logits :contentReference[oaicite:7]{index=7}\n",
    "    preds = logits.argmax(dim=-1)\n",
    "    correct += (preds == labels).sum().item()\n",
    "    total   += labels.size(0)\n",
    "    break  # just one batch for smoke test\n",
    "\n",
    "print(f\"Batch accuracy: {correct/total:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5d2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8199c50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/5 — Loss: 0.0412\n",
      "Epoch 2/5 — Loss: 0.0264\n",
      "Epoch 3/5 — Loss: 0.0199\n",
      "Epoch 4/5 — Loss: 0.0176\n",
      "Epoch 5/5 — Loss: 0.0161\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Resize, Grayscale, ToTensor, Normalize\n",
    "\n",
    "# 0. Device selection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 1. Data transforms & datasets\n",
    "transform = Compose([\n",
    "    Resize(224),\n",
    "    Grayscale(num_output_channels=3),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "train_ds = MNIST(\"data\", train=True,  download=True, transform=transform)\n",
    "test_ds  = MNIST(\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# 2. DataLoaders with pinned memory for faster transfers\n",
    "loader_kwargs = {\n",
    "    \"batch_size\": 32,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 4,     # parallel data loading\n",
    "    \"pin_memory\": True    # page-locked memory for non-blocking copies\n",
    "}\n",
    "train_loader = DataLoader(train_ds, **loader_kwargs)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "\n",
    "# 3. Model initialization & move to GPU\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"farleyknight-org-username/vit-base-mnist\"\n",
    ")\n",
    "model.to(device)           # move model parameters/buffers to GPU\n",
    "model.train()\n",
    "\n",
    "# 4. Optimizer & loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 5. Training loop with GPU data transfers\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for pixel_values, labels in train_loader:\n",
    "        # move batch to GPU with non-blocking pin-memory transfer\n",
    "        pixel_values = pixel_values.to(device, non_blocking=True)\n",
    "        labels       = labels.to(device,       non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(pixel_values=pixel_values).logits\n",
    "        loss   = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs} — Loss: {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddffa33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fdb048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035f61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a61160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchattacks\n",
      "  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\n",
      "Requirement already satisfied: torch>=1.7.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torchattacks) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torchattacks) (0.20.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torchattacks) (1.10.1)\n",
      "Requirement already satisfied: tqdm>=4.56.1 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torchattacks) (4.67.1)\n",
      "Collecting requests~=2.25.1 (from torchattacks)\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy>=1.19.4 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torchattacks) (1.24.3)\n",
      "Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from requests~=2.25.1->torchattacks) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch>=1.7.1->torchattacks) (3.13.1)\n",
      "Collecting typing-extensions>=4.8.0 (from torch>=1.7.1->torchattacks)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch>=1.7.1->torchattacks) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch>=1.7.1->torchattacks) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch>=1.7.1->torchattacks) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torch>=1.7.1->torchattacks) (2024.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from torchvision>=0.8.2->torchattacks) (10.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from tqdm>=4.56.1->torchattacks) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\n",
      "Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
      "Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, idna, chardet, requests, torchattacks\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "Successfully installed chardet-4.0.0 idna-2.10 requests-2.25.1 torchattacks-3.5.1 typing-extensions-4.13.2 urllib3-1.26.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.1.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\n",
      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\n",
      "tensorflow-probability 0.21.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.13.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "344b1d15",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     17\u001b[0m                          num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 1. Load & wrap model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m hf_model \u001b[38;5;241m=\u001b[39m \u001b[43mViTForImageClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfarleyknight-org-username/vit-base-mnist\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mViTWrapper\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, hf_model):\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\transformers\\modeling_utils.py:3157\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3156\u001b[0m         )\n\u001b[1;32m-> 3157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 780 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1155\u001b[0m             device,\n\u001b[0;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m             non_blocking,\n\u001b[0;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Resize, Grayscale, ToTensor, Normalize\n",
    "from torchattacks import FGSM, PGD\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data\n",
    "transform = Compose([Resize(224), Grayscale(3), ToTensor(),\n",
    "                     Normalize([0.5]*3, [0.5]*3)])\n",
    "test_ds = MNIST(\"data\", train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False,\n",
    "                         num_workers=4, pin_memory=True)\n",
    "\n",
    "# 1. Load & wrap model\n",
    "hf_model = ViTForImageClassification.from_pretrained(\n",
    "    \"farleyknight-org-username/vit-base-mnist\"\n",
    ").to(device).eval()\n",
    "\n",
    "class ViTWrapper(nn.Module):\n",
    "    def __init__(self, hf_model):\n",
    "        super().__init__()\n",
    "        self.hf_model = hf_model\n",
    "    def forward(self, x):\n",
    "        return self.hf_model(pixel_values=x).logits\n",
    "\n",
    "wrapped_model = ViTWrapper(hf_model).to(device).eval()\n",
    "\n",
    "# 2. Attacks\n",
    "fgsm_attack = FGSM(wrapped_model, eps=0.1)\n",
    "pgd_attack  = PGD(wrapped_model, eps=8/255, alpha=2/255, steps=5,\n",
    "                  random_start=True)\n",
    "\n",
    "# 3. Evaluation helper\n",
    "def evaluate_attack(attack, name):\n",
    "    correct, total = 0, 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_adv = attack(x, y)\n",
    "        with torch.no_grad():\n",
    "            logits = hf_model(pixel_values=x_adv).logits\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total   += y.size(0)\n",
    "    print(f\"{name} accuracy: {correct/total:.2%}\")\n",
    "\n",
    "# 4. Run evaluations\n",
    "print(\"Clean accuracy:\")\n",
    "evaluate_attack(lambda x,y: x, \"Clean\")  # identity attack prints baseline\n",
    "evaluate_attack(fgsm_attack, \"FGSM\")\n",
    "evaluate_attack(pgd_attack,  \"PGD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26add6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33285867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[5]:\n",
    "def make_adv_loader(model, attack, loader, device):\n",
    "    model.eval()\n",
    "    X_adv, Y_adv = [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_adv = attack(x, y)\n",
    "        X_adv.append(x_adv.detach().cpu())\n",
    "        Y_adv.append(y.detach().cpu())\n",
    "    X_adv = torch.cat(X_adv)\n",
    "    Y_adv = torch.cat(Y_adv)\n",
    "    ds = TensorDataset(X_adv, Y_adv)\n",
    "    return DataLoader(ds, batch_size=64, shuffle=False,\n",
    "                      num_workers=4, pin_memory=(device.type==\"cuda\"))\n",
    "\n",
    "# In[6]:\n",
    "fgsm_loader = make_adv_loader(wrapped_model, fgsm_attack, test_loader, device)\n",
    "pgd_loader  = make_adv_loader(wrapped_model, pgd_attack,  test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ab7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "149b05e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "class FeatureSqueezeDetector(nn.Module):\n",
    "    def __init__(self, model): super().__init__(); self.model = model\n",
    "    def score(self, x):\n",
    "        x_s = torch.floor(x*15)/15\n",
    "        p = F.softmax(self.model(x),   dim=-1)\n",
    "        q = F.softmax(self.model(x_s), dim=-1)\n",
    "        return (p-q).abs().sum(dim=1)\n",
    "\n",
    "class AutoencoderDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3,16,3,2,1), nn.ReLU(),\n",
    "            nn.Conv2d(16,8,3,2,1), nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8,16,3,2,1,1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16,3,3,2,1,1), nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "    def score(self, x):\n",
    "        recon = self(x)\n",
    "        return ((x-recon)**2).mean(dim=[1,2,3])\n",
    "\n",
    "# move AE to device\n",
    "ae_detector = AutoencoderDetector().to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc844576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f975ac6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.99 GiB of which 0 bytes is free. Of the allocated memory 28.75 GiB is allocated by PyTorch, and 588.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m fsd \u001b[38;5;241m=\u001b[39m FeatureSqueezeDetector(wrapped_model)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 7\u001b[0m fs_scores \u001b[38;5;241m=\u001b[39m \u001b[43mfsd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m ae_scores \u001b[38;5;241m=\u001b[39m ae_detector\u001b[38;5;241m.\u001b[39mscore(x_batch)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature-Squeeze scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m, fs_scores[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36mFeatureSqueezeDetector.score\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 5\u001b[0m     x_s \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m15\u001b[39m\n\u001b[0;32m      6\u001b[0m     p \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x),   dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m     q \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x_s), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 15.99 GiB of which 0 bytes is free. Of the allocated memory 28.75 GiB is allocated by PyTorch, and 588.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# In[8]:\n",
    "# Take first batch from FGSM loader\n",
    "x_batch, _ = next(iter(fgsm_loader))\n",
    "x_batch = x_batch.to(device, non_blocking=True)\n",
    "\n",
    "fsd = FeatureSqueezeDetector(wrapped_model).to(device).eval()\n",
    "fs_scores = fsd.score(x_batch)\n",
    "ae_scores = ae_detector.score(x_batch)\n",
    "\n",
    "print(\"Feature-Squeeze scores:\", fs_scores[:5].detach().cpu().numpy())\n",
    "print(\"Autoencoder scores:    \", ae_scores[:5].detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc82f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f9e7b4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 38, in do_one_step\n    data = pin_memory(data, device)\n  File \"c:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 89, in pin_memory\n    clone[i] = pin_memory(item, device)\n  File \"c:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 59, in pin_memory\n    return data.pin_memory(device)\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m fs_detector \u001b[38;5;241m=\u001b[39m FeatureSqueezeDetector(wrapped_model)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 1) Collect scores\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m fs_clean \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs_detector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m fs_fgsm  \u001b[38;5;241m=\u001b[39m collect_scores(fs_detector, fgsm_loader)\n\u001b[0;32m     39\u001b[0m fs_pgd   \u001b[38;5;241m=\u001b[39m collect_scores(fs_detector, pgd_loader)\n",
      "Cell \u001b[1;32mIn[23], line 21\u001b[0m, in \u001b[0;36mcollect_scores\u001b[1;34m(detector, loader, sub_batch)\u001b[0m\n\u001b[0;32m     19\u001b[0m all_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, _ \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     22\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m         scores \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 38, in do_one_step\n    data = pin_memory(data, device)\n  File \"c:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 89, in pin_memory\n    clone[i] = pin_memory(item, device)\n  File \"c:\\Users\\Abhis\\.conda\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 59, in pin_memory\n    return data.pin_memory(device)\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "# In[8]: Evaluate detectors on clean, FGSM, and PGD sets\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume these exist from prior cells:\n",
    "#   test_loader      – clean MNIST DataLoader\n",
    "#   fgsm_loader      – FGSM adversarial DataLoader\n",
    "#   pgd_loader       – PGD adversarial DataLoader\n",
    "#   fs_detector      – FeatureSqueezeDetector(wrapped_model).to(device).eval()\n",
    "#   ae_detector      – AutoencoderDetector().to(device).eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collect_scores(detector, loader, sub_batch=16):\n",
    "    detector.eval()\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            scores = []\n",
    "            for i in range(0, x.size(0), sub_batch):\n",
    "                chunk = x[i:i+sub_batch]\n",
    "                s = detector.score(chunk)\n",
    "                scores.append(s.detach().cpu())\n",
    "            all_scores.append(torch.cat(scores))\n",
    "            torch.cuda.empty_cache()\n",
    "    return torch.cat(all_scores).numpy()\n",
    "\n",
    "# In[9]: Instantiate the Feature‐Squeeze detector\n",
    "fs_detector = FeatureSqueezeDetector(wrapped_model).to(device).eval()\n",
    "\n",
    "\n",
    "# 1) Collect scores\n",
    "fs_clean = collect_scores(fs_detector, test_loader)\n",
    "fs_fgsm  = collect_scores(fs_detector, fgsm_loader)\n",
    "fs_pgd   = collect_scores(fs_detector, pgd_loader)\n",
    "\n",
    "ae_clean = collect_scores(ae_detector, test_loader)\n",
    "ae_fgsm  = collect_scores(ae_detector, fgsm_loader)\n",
    "ae_pgd   = collect_scores(ae_detector, pgd_loader)\n",
    "\n",
    "# 2) Build labels & score arrays\n",
    "y_clean = np.zeros_like(fs_clean)\n",
    "y_adv   = np.ones_like (fs_fgsm)      # we’ll treat FGSM/PGD both as positive\n",
    "y_true  = np.concatenate([y_clean, y_adv, y_adv])\n",
    "\n",
    "fs_scores = np.concatenate([fs_clean, fs_fgsm, fs_pgd])\n",
    "ae_scores = np.concatenate([ae_clean, ae_fgsm, ae_pgd])\n",
    "\n",
    "# 3) ROC & AUC\n",
    "fpr_fs, tpr_fs, _ = roc_curve(y_true, fs_scores, pos_label=1)\n",
    "roc_auc_fs       = auc(fpr_fs, tpr_fs)\n",
    "fpr_ae, tpr_ae, _ = roc_curve(y_true, ae_scores, pos_label=1)\n",
    "roc_auc_ae       = auc(fpr_ae, tpr_ae)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_fs, tpr_fs, label=f'Feature-Squeeze (AUC={roc_auc_fs:.2f})')\n",
    "plt.plot(fpr_ae, tpr_ae, label=f'Autoencoder  (AUC={roc_auc_ae:.2f})')\n",
    "plt.plot([0,1],[0,1],'k--',alpha=0.3)\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves'); plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# 4) Precision–Recall & AP\n",
    "prec_fs, rec_fs, _ = precision_recall_curve(y_true, fs_scores, pos_label=1)\n",
    "ap_fs             = auc(rec_fs, prec_fs)\n",
    "prec_ae, rec_ae, _ = precision_recall_curve(y_true, ae_scores, pos_label=1)\n",
    "ap_ae             = auc(rec_ae, prec_ae)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(rec_fs, prec_fs, label=f'FS (AP={ap_fs:.2f})')\n",
    "plt.plot(rec_ae, prec_ae, label=f'AE (AP={ap_ae:.2f})')\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "plt.title('Precision–Recall Curves'); plt.legend(loc='lower left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038bba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU Torch)",
   "language": "python",
   "name": "torch_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
